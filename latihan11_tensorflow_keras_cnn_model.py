# -*- coding: utf-8 -*-
"""latihan11-tensorflow-keras-cnn-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3OP-7COboTfgSrPs5SOw6zVM4L_NIw-
"""

# Tahapan latihan kali ini adalah:
# Memastikan TensorFlow yang digunakan di Google Colab adalah versi di atas 2.0.
# Mengunduh dataset dan melakukan extract file dengan metode unzip.
# Menampung direktori setiap kelas pada direktori train dan validasi ke dalam variabel.
# Pre-processing data dengan image augmentation.
# Mempersiapkan data latih yang akan dipelajari oleh model.
# Membangun arsitektur model dengan Convolutional Neural Network (CNN).
# Compile dan latih model dengan model.compile dan model.fit hingga mendapatkan akurasi yang diinginkan
# Menguji model yang telah dibuat dengan menggunakan gambar yang belum dikenali oleh model.

import tensorflow as tf
print(tf.__version__)

# mempersiapkan dataset yang akan digunakan
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/raw/main/ml_pemula_academy/messy-vs-clean-room.zip \
  -O /tmp/messy_vs_clean_room.zip

# melakukan ekstraksi pada file zip
import zipfile, os

# Menentukan path ke file ZIP yang akan diekstrak
local_zip = '/tmp/messy_vs_clean_room.zip'

# Membuka file ZIP untuk diekstrak
zip_ref = zipfile.ZipFile(local_zip, 'r')

# Mengekstrak semua isi file ZIP ke dalam direktori /tmp
zip_ref.extractall('/tmp')

# Menutup file ZIP setelah proses ekstraksi selesai
zip_ref.close()

# Menentukan direktori base untuk data gambar
base_dir = '/tmp/images'

# Menentukan direktori untuk data pelatihan dan validasi
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

# import zipfile, os: Mengimpor modul zipfile dan os yang digunakan untuk bekerja dengan file ZIP dan sistem operasi, masing-masing.
# local_zip = '/tmp/messy_vs_clean_room.zip': Menentukan path dari file ZIP yang akan diekstrak.
# zip_ref = zipfile.ZipFile(local_zip, 'r'): Membuka file ZIP dengan mode baca ('r').
# zip_ref.extractall('/tmp'): Mengekstrak semua isi dari file ZIP ke dalam direktori /tmp.
# zip_ref.close(): Menutup file ZIP setelah proses ekstraksi selesai.
# base_dir = '/tmp/images': Menentukan direktori base tempat data gambar akan disimpan.
# train_dir = os.path.join(base_dir, 'train') dan validation_dir = os.path.join(base_dir, 'val')
# : Menentukan direktori khusus untuk data pelatihan (train) dan validasi (val).
# os.listdir('/tmp/images/train') dan os.listdir('/tmp/images/val'): Menampilkan daftar file
#  di direktori pelatihan dan validasi, mungkin untuk memeriksa apakah proses ekstraksi berhasil.

# Menampilkan daftar file di direktori pelatihan
os.listdir('/tmp/images/train')

# Menampilkan daftar file di direktori validasi
os.listdir('/tmp/images/val')

# preprocessing data, pelabelan sampel otomatis, dan augmentasi gambar.
# ImageDataGenerator untuk data latih dan data validasi. ImageDataGenerator
# merupakan sebuah fungsi yang sangat berguna untuk mempersiapkan data latih dan data validasi.
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

validation_datagen = ImageDataGenerator(
                    rescale=1./255)

# Mempersiapkan data latih yang akan dipelajari oleh model.
train_generator = train_datagen.flow_from_directory(
        train_dir,  # direktori data latih
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4,
        # karena ini merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'
        class_mode='binary')

validation_generator = validation_datagen.flow_from_directory(
        validation_dir, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=4,
        # karena ini merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'
        class_mode='binary')

# membuat model
# penggunaan empat layer konvolusi bertujuan untuk mengekstraksi fitur-fitur
# hierarkis yang semakin kompleks dari gambar. Setiap layer konvolusi memiliki
# beberapa filter yang belajar untuk mendeteksi pola atau fitur tertentu pada
# tingkat yang semakin abstrak

# Max pooling membantu mengurangi dimensi spasial gambar, sehingga model dapat
# mempelajari hierarki fitur spasial secara bertingkat. Setiap layer max pooling
# menyusutkan ukuran gambar, tetapi mempertahankan fitur-fitur yang signifikan,
# sehingga model dapat membangun pemahaman yang semakin kompleks
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
#Mengubah output dari layer sebelumnya (yang berupa matriks) menjadi satu dimensi.
    tf.keras.layers.Flatten(),
#Fully connected layer dengan 512 neuron
    tf.keras.layers.Dense(512, activation='relu'),
#Fully connected layer terakhir dengan satu neuron dan fungsi aktivasi sigmoid.
# untuk tugas klasifikasi biner
    tf.keras.layers.Dense(1, activation='sigmoid')
])

'''
mode summary
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 148, 148, 32)      896

 max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0
 D)

 conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496

 max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0
 g2D)

 conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856

 max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0
 g2D)

 conv2d_3 (Conv2D)           (None, 15, 15, 512)       590336

 max_pooling2d_3 (MaxPoolin  (None, 7, 7, 512)         0
 g2D)

 flatten (Flatten)           (None, 25088)             0

 dense (Dense)               (None, 512)               12845568

 dense_1 (Dense)             (None, 1)                 513

=================================================================
Total params: 13529665 (51.61 MB)
Trainable params: 13529665 (51.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
'''

'''
Pada kasus klasifikasi biner, output model merupakan angka tunggal
antara 0 dan 1. Sehingga, kita set dense layer terakhir = 1.
Sementara itu, kolom “Param #” berisi informasi
mengenai jumlah parameter pada tiap layer.

“Output Shape” berisi informasi ukuran output yang dihasilkan tiap layer.
ukuran input gambar yang telah didefinisikan sebelumnya sebesar (150, 150).
Tapi pada convolutional layer pertama, setiap satu input gambar akan
menghasilkan ukuran output (148, 148) sebanyak 32
gambar.

Ukuran tersebut berkurang karena pake filter dengan
ukuran (3, 3) dengan jumlah filter sebanyak 32 filter. Sehingga, tiap
satu input gambar akan menghasilkan 32 gambar baru dengan ukuran (148, 148).

flatten layer. Output dari MaxPoling layer terakhir yang terdiri dari 512
gambar dengan ukuran (7, 7) akan diubah ke dalam bentuk array 1D (tensor 1D).
 Hal ini  akan menghasilkan output berukuran (25088).

output tersebut kemudian masuk ke dalam dense layer pertama yang memiliki
512 neuron. Sehingga, ia akan menghasilkan output dengan ukuran (512).
Selanjutnya, output ini akan masuk pada dense layer kedua yang memiliki
1 neuron sehingga akan menghasilkan output dengan ukuran (1).
'''

# compile model dengan 'adam' optimizer loss function 'binary_crossentropy'
model.compile(loss='binary_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch
      epochs=25,
      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi
      validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch
      verbose=2)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  print(fn)
  if classes==1:
   print('messy')
  else:
   print('clean')

print(train_generator.class_indices)

